{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the problem\n",
    "For this program we are going to be working with a dataset, breast-cancer.csv. This is a dataset that has several different attributes that describe tumors found in the breast. Along with the attributes of the tumor, the dataset also has an output which is the diagnostic column. This column contains whether each each tumor was malignant or benign. We will be using all of the attributes(shown below) to train a model to predict whether or not a given tumor is malignant or benign. This makes our problem one of Binary Classification. We will be spliting our dataset into training and testing subsets in order to train and test our model. Upon completing the training of our model, we will calculate an accuracy score of the model as well as populate a classification report containing the precision and recall of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'diagnosis',\n",
       " 'radius_mean',\n",
       " 'texture_mean',\n",
       " 'perimeter_mean',\n",
       " 'area_mean',\n",
       " 'smoothness_mean',\n",
       " 'compactness_mean',\n",
       " 'concavity_mean',\n",
       " 'concave points_mean',\n",
       " 'symmetry_mean',\n",
       " 'fractal_dimension_mean',\n",
       " 'radius_se',\n",
       " 'texture_se',\n",
       " 'perimeter_se',\n",
       " 'area_se',\n",
       " 'smoothness_se',\n",
       " 'compactness_se',\n",
       " 'concavity_se',\n",
       " 'concave points_se',\n",
       " 'symmetry_se',\n",
       " 'fractal_dimension_se',\n",
       " 'radius_worst',\n",
       " 'texture_worst',\n",
       " 'perimeter_worst',\n",
       " 'area_worst',\n",
       " 'smoothness_worst',\n",
       " 'compactness_worst',\n",
       " 'concavity_worst',\n",
       " 'concave points_worst',\n",
       " 'symmetry_worst',\n",
       " 'fractal_dimension_worst']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing dataset\n",
    "dataSet = pd.read_csv('./data/breast-cancer.csv')\n",
    "\n",
    "# Shuffling dataset\n",
    "data = dataSet.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Showing all current attributes in the Dataset \n",
    "data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>867387</td>\n",
       "      <td>B</td>\n",
       "      <td>15.71</td>\n",
       "      <td>13.93</td>\n",
       "      <td>102.00</td>\n",
       "      <td>761.7</td>\n",
       "      <td>0.09462</td>\n",
       "      <td>0.09462</td>\n",
       "      <td>0.07135</td>\n",
       "      <td>0.05933</td>\n",
       "      <td>...</td>\n",
       "      <td>17.50</td>\n",
       "      <td>19.25</td>\n",
       "      <td>114.30</td>\n",
       "      <td>922.8</td>\n",
       "      <td>0.1223</td>\n",
       "      <td>0.1949</td>\n",
       "      <td>0.1709</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.2723</td>\n",
       "      <td>0.07071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>911296201</td>\n",
       "      <td>M</td>\n",
       "      <td>17.08</td>\n",
       "      <td>27.15</td>\n",
       "      <td>111.20</td>\n",
       "      <td>930.9</td>\n",
       "      <td>0.09898</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.10070</td>\n",
       "      <td>0.06431</td>\n",
       "      <td>...</td>\n",
       "      <td>22.96</td>\n",
       "      <td>34.49</td>\n",
       "      <td>152.10</td>\n",
       "      <td>1648.0</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.2639</td>\n",
       "      <td>0.15550</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.09060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>874839</td>\n",
       "      <td>B</td>\n",
       "      <td>12.30</td>\n",
       "      <td>15.90</td>\n",
       "      <td>78.83</td>\n",
       "      <td>463.7</td>\n",
       "      <td>0.08080</td>\n",
       "      <td>0.07253</td>\n",
       "      <td>0.03844</td>\n",
       "      <td>0.01654</td>\n",
       "      <td>...</td>\n",
       "      <td>13.35</td>\n",
       "      <td>19.59</td>\n",
       "      <td>86.65</td>\n",
       "      <td>546.7</td>\n",
       "      <td>0.1096</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1423</td>\n",
       "      <td>0.04815</td>\n",
       "      <td>0.2482</td>\n",
       "      <td>0.06306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89382602</td>\n",
       "      <td>B</td>\n",
       "      <td>12.76</td>\n",
       "      <td>13.37</td>\n",
       "      <td>82.29</td>\n",
       "      <td>504.1</td>\n",
       "      <td>0.08794</td>\n",
       "      <td>0.07948</td>\n",
       "      <td>0.04052</td>\n",
       "      <td>0.02548</td>\n",
       "      <td>...</td>\n",
       "      <td>14.19</td>\n",
       "      <td>16.40</td>\n",
       "      <td>92.04</td>\n",
       "      <td>618.8</td>\n",
       "      <td>0.1194</td>\n",
       "      <td>0.2208</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>0.08411</td>\n",
       "      <td>0.2564</td>\n",
       "      <td>0.08253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8712766</td>\n",
       "      <td>M</td>\n",
       "      <td>17.47</td>\n",
       "      <td>24.68</td>\n",
       "      <td>116.10</td>\n",
       "      <td>984.6</td>\n",
       "      <td>0.10490</td>\n",
       "      <td>0.16030</td>\n",
       "      <td>0.21590</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>23.14</td>\n",
       "      <td>32.33</td>\n",
       "      <td>155.30</td>\n",
       "      <td>1660.0</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>0.4890</td>\n",
       "      <td>0.17210</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>0.09300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0     867387         B        15.71         13.93          102.00      761.7   \n",
       "1  911296201         M        17.08         27.15          111.20      930.9   \n",
       "2     874839         B        12.30         15.90           78.83      463.7   \n",
       "3   89382602         B        12.76         13.37           82.29      504.1   \n",
       "4    8712766         M        17.47         24.68          116.10      984.6   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.09462           0.09462         0.07135              0.05933   \n",
       "1          0.09898           0.11100         0.10070              0.06431   \n",
       "2          0.08080           0.07253         0.03844              0.01654   \n",
       "3          0.08794           0.07948         0.04052              0.02548   \n",
       "4          0.10490           0.16030         0.21590              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         17.50          19.25           114.30       922.8   \n",
       "1  ...         22.96          34.49           152.10      1648.0   \n",
       "2  ...         13.35          19.59            86.65       546.7   \n",
       "3  ...         14.19          16.40            92.04       618.8   \n",
       "4  ...         23.14          32.33           155.30      1660.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1223             0.1949           0.1709               0.13740   \n",
       "1            0.1600             0.2444           0.2639               0.15550   \n",
       "2            0.1096             0.1650           0.1423               0.04815   \n",
       "3            0.1194             0.2208           0.1769               0.08411   \n",
       "4            0.1376             0.3830           0.4890               0.17210   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.2723                  0.07071  \n",
       "1          0.3010                  0.09060  \n",
       "2          0.2482                  0.06306  \n",
       "3          0.2564                  0.08253  \n",
       "4          0.2160                  0.09300  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing a few rows of the dataset\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Exploring our data  \n",
    "Upon reviewing the dataset, I see that I'm very fortunate to have a dataset that is very easy to work with. This dataset, obtained from kaggle, was designed to be very convinent for people to train models with. If you would like to see the dataset for yourself, it can be found at https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset?select=breast-cancer.csv. Despite the convinient parts of the dataset, there are some aspects that I would like to update. We will be dropping the ID column as those values are entirely independent of the each diagnosis and having them could negatively affect our accuracy. Furthermore, you will see below that the diagnosis (our output) is in the form of a string. More specifically, the diagnosis is an M for malignant, and a B for benign. I prefer to change these values to a 1 for malignant, and a 0 for benign. I find integers easier to work with when drawing conclusions on the efficiency of our model, so we will be updating these values to make the dataset easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping id column and giving our updated \n",
    "# dataset a new reference variable\n",
    "myData = data.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  fractal_dimension_mean  ...  radius_worst  \\\n",
       "count     569.000000              569.000000  ...    569.000000   \n",
       "mean        0.181162                0.062798  ...     16.269190   \n",
       "std         0.027414                0.007060  ...      4.833242   \n",
       "min         0.106000                0.049960  ...      7.930000   \n",
       "25%         0.161900                0.057700  ...     13.010000   \n",
       "50%         0.179200                0.061540  ...     14.970000   \n",
       "75%         0.195700                0.066120  ...     18.790000   \n",
       "max         0.304000                0.097440  ...     36.040000   \n",
       "\n",
       "       texture_worst  perimeter_worst   area_worst  smoothness_worst  \\\n",
       "count     569.000000       569.000000   569.000000        569.000000   \n",
       "mean       25.677223       107.261213   880.583128          0.132369   \n",
       "std         6.146258        33.602542   569.356993          0.022832   \n",
       "min        12.020000        50.410000   185.200000          0.071170   \n",
       "25%        21.080000        84.110000   515.300000          0.116600   \n",
       "50%        25.410000        97.660000   686.500000          0.131300   \n",
       "75%        29.720000       125.400000  1084.000000          0.146000   \n",
       "max        49.540000       251.200000  4254.000000          0.222600   \n",
       "\n",
       "       compactness_worst  concavity_worst  concave points_worst  \\\n",
       "count         569.000000       569.000000            569.000000   \n",
       "mean            0.254265         0.272188              0.114606   \n",
       "std             0.157336         0.208624              0.065732   \n",
       "min             0.027290         0.000000              0.000000   \n",
       "25%             0.147200         0.114500              0.064930   \n",
       "50%             0.211900         0.226700              0.099930   \n",
       "75%             0.339100         0.382900              0.161400   \n",
       "max             1.058000         1.252000              0.291000   \n",
       "\n",
       "       symmetry_worst  fractal_dimension_worst  \n",
       "count      569.000000               569.000000  \n",
       "mean         0.290076                 0.083946  \n",
       "std          0.061867                 0.018061  \n",
       "min          0.156500                 0.055040  \n",
       "25%          0.250400                 0.071460  \n",
       "50%          0.282200                 0.080040  \n",
       "75%          0.317900                 0.092080  \n",
       "max          0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Presenting statistical information of the attributes\n",
    "myData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.71</td>\n",
       "      <td>13.93</td>\n",
       "      <td>102.00</td>\n",
       "      <td>761.7</td>\n",
       "      <td>0.09462</td>\n",
       "      <td>0.09462</td>\n",
       "      <td>0.07135</td>\n",
       "      <td>0.05933</td>\n",
       "      <td>0.1816</td>\n",
       "      <td>...</td>\n",
       "      <td>17.50</td>\n",
       "      <td>19.25</td>\n",
       "      <td>114.30</td>\n",
       "      <td>922.8</td>\n",
       "      <td>0.1223</td>\n",
       "      <td>0.1949</td>\n",
       "      <td>0.1709</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.2723</td>\n",
       "      <td>0.07071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.08</td>\n",
       "      <td>27.15</td>\n",
       "      <td>111.20</td>\n",
       "      <td>930.9</td>\n",
       "      <td>0.09898</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.10070</td>\n",
       "      <td>0.06431</td>\n",
       "      <td>0.1793</td>\n",
       "      <td>...</td>\n",
       "      <td>22.96</td>\n",
       "      <td>34.49</td>\n",
       "      <td>152.10</td>\n",
       "      <td>1648.0</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.2639</td>\n",
       "      <td>0.15550</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.09060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.30</td>\n",
       "      <td>15.90</td>\n",
       "      <td>78.83</td>\n",
       "      <td>463.7</td>\n",
       "      <td>0.08080</td>\n",
       "      <td>0.07253</td>\n",
       "      <td>0.03844</td>\n",
       "      <td>0.01654</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>...</td>\n",
       "      <td>13.35</td>\n",
       "      <td>19.59</td>\n",
       "      <td>86.65</td>\n",
       "      <td>546.7</td>\n",
       "      <td>0.1096</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1423</td>\n",
       "      <td>0.04815</td>\n",
       "      <td>0.2482</td>\n",
       "      <td>0.06306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.76</td>\n",
       "      <td>13.37</td>\n",
       "      <td>82.29</td>\n",
       "      <td>504.1</td>\n",
       "      <td>0.08794</td>\n",
       "      <td>0.07948</td>\n",
       "      <td>0.04052</td>\n",
       "      <td>0.02548</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>...</td>\n",
       "      <td>14.19</td>\n",
       "      <td>16.40</td>\n",
       "      <td>92.04</td>\n",
       "      <td>618.8</td>\n",
       "      <td>0.1194</td>\n",
       "      <td>0.2208</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>0.08411</td>\n",
       "      <td>0.2564</td>\n",
       "      <td>0.08253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.47</td>\n",
       "      <td>24.68</td>\n",
       "      <td>116.10</td>\n",
       "      <td>984.6</td>\n",
       "      <td>0.10490</td>\n",
       "      <td>0.16030</td>\n",
       "      <td>0.21590</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>...</td>\n",
       "      <td>23.14</td>\n",
       "      <td>32.33</td>\n",
       "      <td>155.30</td>\n",
       "      <td>1660.0</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>0.4890</td>\n",
       "      <td>0.17210</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>0.09300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0        0.0        15.71         13.93          102.00      761.7   \n",
       "1        1.0        17.08         27.15          111.20      930.9   \n",
       "2        0.0        12.30         15.90           78.83      463.7   \n",
       "3        0.0        12.76         13.37           82.29      504.1   \n",
       "4        1.0        17.47         24.68          116.10      984.6   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.09462           0.09462         0.07135              0.05933   \n",
       "1          0.09898           0.11100         0.10070              0.06431   \n",
       "2          0.08080           0.07253         0.03844              0.01654   \n",
       "3          0.08794           0.07948         0.04052              0.02548   \n",
       "4          0.10490           0.16030         0.21590              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.1816  ...         17.50          19.25           114.30   \n",
       "1         0.1793  ...         22.96          34.49           152.10   \n",
       "2         0.1667  ...         13.35          19.59            86.65   \n",
       "3         0.1601  ...         14.19          16.40            92.04   \n",
       "4         0.1538  ...         23.14          32.33           155.30   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0       922.8            0.1223             0.1949           0.1709   \n",
       "1      1648.0            0.1600             0.2444           0.2639   \n",
       "2       546.7            0.1096             0.1650           0.1423   \n",
       "3       618.8            0.1194             0.2208           0.1769   \n",
       "4      1660.0            0.1376             0.3830           0.4890   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0               0.13740          0.2723                  0.07071  \n",
       "1               0.15550          0.3010                  0.09060  \n",
       "2               0.04815          0.2482                  0.06306  \n",
       "3               0.08411          0.2564                  0.08253  \n",
       "4               0.17210          0.2160                  0.09300  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Updating diagnosis values 1 for malginant and 0 for benign\n",
    "myData['diagnosis'] = myData['diagnosis'].apply(lambda x: x.replace(\"B\", \"0\"))\n",
    "myData['diagnosis'] = myData['diagnosis'].apply(lambda x: x.replace(\"M\", \"1\"))\n",
    "\n",
    "# Keeping datatypes consistent\n",
    "myData = myData.astype(float)\n",
    "\n",
    "# Presenting the same 5 rows of the dataset as before to verify that M is now 1, B is now 0, and the ID column is removed.\n",
    "myData[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569,)\n",
      "[0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 1 0 0\n",
      " 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1\n",
      " 0 0 0 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1\n",
      " 1 0 1 0 0 1 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1\n",
      " 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 1 1 1 1\n",
      " 1 0 0 1 0 1 0 0 1 0 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 1\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0\n",
      " 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 0 1\n",
      " 1 0 0 1 1 1 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Populating X and y values as we prepare to split our data\n",
    "X = myData.iloc[:,1:32].values\n",
    "y = myData.iloc[:,0].values\n",
    "\n",
    "# Updating y (diagnosis) values to integers since we do not need floats for them\n",
    "y = y.astype(int)\n",
    "\n",
    "# Printing the shapes of X and y to make sure we have the right amount of columns and rows for each\n",
    "# (Should be 30 columns for X and 1 for y)\n",
    "# As we can see below, we have the right dimensions!\n",
    "print(np.shape(X))\n",
    "print(np.shape(y))\n",
    "\n",
    "# Double checking our y to make sure nothing unexpected happened. Looks good!\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569\n",
      "455\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing\n",
    "# I prefer the 80/20 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=10\n",
    ")\n",
    "print(len(myData))\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Training and Evaluating the model using logistic regression  \n",
    "I decided to use Logistic Regression for this particular dataset for three main reasons: Firstly, it is rather straighforward. Secondly, it's implementation is simple. And finally, upon looking into each model that I've experienced, I found Logisitic Regression to be the most effecting with problems regarding binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Importing Classification Report\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must increase number of iterations for this particular dataset to ensure convergence\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  94.74 %\n"
     ]
    }
   ],
   "source": [
    "# Creating a fit for our model\n",
    "lr.fit(x_train,y_train)\n",
    "\n",
    "# Generating predictions for the diagnosis\n",
    "predictions = lr.predict(x_test)\n",
    "\n",
    "# Calculating a score for how accurate our models predictions were compared to the actual data\n",
    "score = lr.score(x_test,y_test)\n",
    "print('Score: ',\"%.2f\" %(score * 100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96        74\n",
      "           1       0.97      0.88      0.92        40\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generating Classifcation Report\n",
    "report = classification_report(y_test, predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Conclusions  \n",
    "While the precision/recall and the accuracy scores do fluctuate each time the runtime is recycled, the highest scores I was able to achieve was an accuracy score of 98%, and both precision and recalls of 0.98 and 0.96 respectively. I'm satisifed with these results as this project took fair amount of time to get these results. Seeing the project be finished with such high accuracy is very satisfying. In the future, I would like to code my own logisitic regression instead of using a library. I would have also enjoyed drawing conclusions on this dataset using different methods (such as Random Trees or KNN) as it would have been enjoyable to see which method could achieve the highest accuracy. Above everything else, I would love to be able to see if I could push my accuracy to be above 98% everytime the runtime is recycled as I was ranging from 93%-98% and I believe that trying other methods could have been a way to achieve that result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
